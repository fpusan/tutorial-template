*************************************
Explanation of SqueezeMeta algorithms
*************************************

.. _lca:
The LCA algorithm
=================

.. _euk annot:
Taxonomic annotation of eukaryotic ORFs
---------------------------------------
By default, SqueezeMeta applies `Luo et al. (2014) <https://pmc.ncbi.nlm.nih.gov/articles/PMC4005636/>`_ identity cutoffs in order to assign an ORF to a given taxonomic rank (see :ref:`lca`). In our tests, these cutoffs resulted in a very low percentage of annotation for eukaryotic ORFs.

The treatment of these ORFs differs depending on how :doc:`SqueezeMeta.pl <execution>`, :ref:`sqm_reads.pl <sqm_reads>` or :ref:`sqm_longreads.pl <sqm_longreads>` are launched, and the result files that are used afterwards.

- The raw results produced by :doc:`SqueezeMeta.pl <execution>`,  :ref:`sqm_reads.pl <sqm_reads>` and :ref:`sqm_longreads.pl <sqm_longreads>` will apply identity cutoffs to all taxa by default unless the flag ``--euk`` is passed when running the script, in which case the identity cutoffs will only be applied to eukaryotic reads.

    - An exception to this is the final step of the *SqueezeMeta* pipeline, which runs :ref:`sqm2tables.py <sqm2tables>` with default parameters, see :ref:`_sqm2tables in pipeline`. In that step, both types of results will be produced regardless of whether the ``--euk`` flag is passed or not, see below.

- When creating taxonomic aggregate tables with :ref:`sqm2tables.py <sqm2tables>` (for projects created with *SqueezeMeta.pl*) and :ref:`sqmreads2tables.py <sqmreads2tables>` (for projects created with :ref:`sqm_reads.pl <sqm_reads>` and :ref:`sqm_longreads.pl <sqm_longreads>`) three sets of results will be generated **regardless of whether the --euk flag was passed when running the script**.
  
    - *allfilter* files, containing ORF, contig and aggregate taxonomies obtained after applying identity filters to ALL taxa.
    - *prokfilter* files, containing ORF, contig and aggregate taxonomies obtained after applying identity filters to prokaryotic taxa only. This would replicate the behaviour of ``--euk`` flag.
    - *nofilter* files, containing ORF, contig and aggregate taxonomies obtained after applying NO identity filters at all.
  
  The advantage of this method is that there is no need to repeat the whole run to change the behaviour of identity cutoffs.

- When using :doc:`SQMtools` to analyze your data, you get to choose the behaviour of identity cutoffs (*allfilter*, *prokfilter*, *nofilter*) through the ``tax_mode`` parameter in the ``loadSQM`` and ``loadSQMlite`` functions (with the default being ``"prokfilter"``, i.e. using identity cutoffs for prokaryotes but not eukaryotes).

Handling of unclassified and missing ranks in NCBI taxonomy
-----------------------------------------------------------
.. note::
   The discussion below applies only to the results generated by :ref:`sqm2tables.py <sqm2tables>` (which it itself ran as the final step of the SqueezeMeta pipeline, see :ref:`_sqm2tables in pipeline`) and :ref:`sqmreads2tables.py <sqmreads2tables>`, and also when loading projects in R with :doc:`SQMtools`. Other SqueezeMeta scripts will not correct for this and report taxonomies directly as received from NCBI. 

SqueezeMeta uses NCBI's nr database for taxonomic annotation, and reports the superkingdom, phylum, class, order, family, genus and species ranks. In some cases, the NCBI taxonomy is missing some intermediate ranks. For example, the NCBI taxonomy for the order *Trichomonadida* is:

- superkingdom: *Eukaryota*
- no rank: *Parabasalia*
- order: *Trichomonadida*

NCBI does not assign Trichomonadida to any taxa in the class and phylum ranks. For clarity, :ref:`sqm2tables.py <sqm2tables>` and :ref:`sqmreads2tables.py <sqmreads2tables>` will indicate this by recycling the highest available taxonomy and adding the ``"(no <rank> in NCBI)"`` string after it. The scripts will also recycle the highest available taxonomy and use it to populate lower level taxonomic ranks, by adding the ``"Unclassified"`` string before it.

For example, ORFs that can be classified down to the *Trichomonadida* order (which itself lacks class and phylum classifications in NCBI) and that could not be classified at the family level or below will be reported as:

- superkingdom: *Eukaryota*
- phylum: *Trichomonadida (no phylum in NCBI)*
- class: *Trichomonadida (no class in NCBI)*
- order: *Trichomonadida*
- family: *Unclassified Trichomonadida*
- genus: *Unclassified Trichomonadida*
- species: *Unclassified Trichomonadida*

.. _nocds:
Meaning of "Unmapped", "Unclassified" and "No CDS" in taxonomy results
----------------------------------------------------------------------
.. note::                                                                                                                               The discussion below applies only to the results generated by :ref:`sqm2tables.py <sqm2tables>` (which it itself ran as the final step of the SqueezeMeta pipeline, see :ref:`_sqm2tables in pipeline`) and :ref:`sqmreads2tables.py <sqmreads2tables>`, and also when loading projects in R with :doc:`SQMtools`.

The "Unclassified" category represents only the features that were classifiable with our method (i.e. contained a protein-coding sequence) but were not actually classified (because they did not have good enough hits to the reference database).

In addition to the normal taxon names and the “Unclassified” category, the results will contain 2 extra categories:

- ``"Unmapped"``: reads not mapping to any contigs.
- ``"No CDS"``: features (or reads mapping to features) that contained no protein-coding sequences (e.g. rRNAs).


.. _consensus tax:
Consensus taxonomic annotation for contigs and bins
===================================================

.. _fun3:
The fun3 algorithm
==================

.. _partial fun counts:
Partial counts for functions in aggregated tables
-------------------------------------------------
.. note::                                                                                                                               The discussion below applies only to the results generated by :ref:`sqm2tables.py <sqm2tables>` (which it itself ran as the final step of the SqueezeMeta pipeline, see :ref:`_sqm2tables in pipeline`) and :ref:`sqmreads2tables.py <sqmreads2tables>`, and also when loading projects in R with :doc:`SQMtools`.

Some ORFs will have multiple KEGG/COG annotations in the :ref:`ORF table <ORF table>`. This is due to their best hit in the KEGG/COG databases actually being annotated with more than one function. The script will split the abundances of those ORFs between the different functions they have been assigned to, which will preserve the total number of reads in the table, but will lead to fractional counts in some cases. If using those tables with methods that expect integer counts, you can just round them as the error will be minimal. 

.. _doublepass:
Doublepass: blastx on contig gaps
=================================

.. _disparity:
Disparity calculation
=====================

.. _COVER:
The COVER algorithm
===================
COVER (used by the :ref:`cover.pl <COVER_script>`) intends to help in the experimental design of metagenomics by addressing the unavoidable question: How much should I sequence to get good results? Or the other way around: I can spend this much money, would it be worth to use it in sequencing the metagenome?

To answer these questions, COVER allows the estimation of the amount of sequencing needed to achieve a particular objective, being this the coverage attained for the most abundant N members of the microbiome. For instance, how much sequence is needed to reach 5x coverage for the four most abundant members (from now on, OTUs). COVER was first published in 2012 (Tamames *et al.*, 2012, *Environ Microbiol Rep.* **4**:335-41), but we are using a different version of the algorithm described there.

COVER needs information on the composition of the microbiome, and that must be
provided as a file containing 16S rRNA sequences obtained by amplicon sequencing of
the target microbiome. If you don’t have that, you can look for a similar sample already
sequenced (for instance, in NCBI's SRA, see below).

The first step is clustering the sequences at the desired identity level (default: 98%) to
produce OTUs. COVER uses cd-hit (Schmieder *et al.*, 2011, *Bioinformatics* **27**:863-4) for
doing this. The abundance of each OTU is also obtained in this step (the number of
sequences in each OTU). Then, a taxonomic annotation step must be done for inferring
genomic size and 16S rRNA copy number for each of the OTUs. This annotation can be
done using the RDP classifier (Wang *et al.*, 2007, *Appl Environ Microbiol* **73**:5261-7), or
Mothur (Schloss *et al.*, 2009, *Appl Environ Microbiol* **75**:7537-41) alignment against the
SILVA database. The latter is the default option. It is slower but provides more accurate
results.

The taxonomic annotation allows to infer the approximate genomic size by comparison
with the size of already sequenced genomes from the same taxon (we've got this
information from NCBI's genome database). In the same way, we inferred the expected
copy number by comparison to the rrnDB database (Stoddard *et al.*, 2014, *Nucleic Acids
Research* doi: 10.1093/nar/gku1201; https://rrndb.umms.med.umich.edu). Obviously,
the most accurate the annotation, the most precise this estimation will be. In case that
the OTU could not be annotated, COVER uses default values of 4 Mb genomic size and 1
for copy number. These values can be greatly inaccurate and affect the results.
Therefore, it is strongly advised that the taxonomic annotation is as good as possible.

In the next step, COVER calculates the probability of sequencing a base for each of the
OTUs. First, the abundance of each OTU is divided by its copy number:

::

  Abundance_n = Raw_abundance_n / Copy_number_n

Then, all abundances are summed, and individual abundances are normalized by this
total abundance.

::

  Corr_abundance_n = Abundance_n / Σn Abundances

The fraction of the microbiome occupied by each OTU, f, is the product of its abundance
by its genomic size

::

  f_n = Corr_abundance_n * Size_n

and the total size of the microbiome is the sum of all individual fractions

::

  F = Σn f_n

Then, the probability of sequencing one base of a particular OTU is the ratio between its
fraction and the total size:

::

  p_n = f_n / F

And the amount of sequence needed (S) to attain coverage C for genome n is then:

::

  S = C * Size_n / p_n

COVER calculates this value of S for the n-th OTU, as specified by the user. Then,
coverages for all other OTUs are also calculated using the last equation and this value of
S:

::

  C_n = S * p_n / Size_n

in the previous calculation, we have assumed that we can calculate abundances for all
members of the microbiome. Obviously this is not true, because there will be a fraction
of unobserved (rare) OTUs that were not sequenced in our 16S. The size of that fraction
will depend on the completeness of our 16S sequencing, which is influenced by the
diversity of the microbiome and by the sequencing depth. This unobserved fraction can
bias greatly the results. Luckily, there is a way to estimate it by means of the Good’s
estimator of sample coverage (Chao & Shen 2003 Environ Ecol Stat 10: 429–443), that
supposses that the fraction of sequence reads corresponding to unobserved OTUs is
approximately equal to the fraction of observed singletons (OTUs with just one
sequence):

::

  U = f_1 / N_OTUs

Both f_1 and N_OTUs are obtained in the OTU clustering step. Then, we just need to correct
the value of S by this value:

::

  S_corrected = S / (1-U)


